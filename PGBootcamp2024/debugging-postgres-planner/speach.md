# Речь
## Титульник

Всем привет. Меня зовут Сергей Соловьев. Я разработчик в компании Тантор. 
Разрабатываю одноименную СУБД.
Сегодня я расскажу об отладке планировщика.

## Обработка запроса

Для начала вспомним о пайплайне обработки запроса. В нем 4 этапа: парсинг
строки запроса, переписывание, планировние и выполнение.

Нам сегодня интересн 3 этап - планирование. Именно здесь и работает планировщик.

В его работе можно также выделить 4 этапа.

Первый этап - предобработка дерева запроса. На этом этапе выполняются общие 
оптимизации. Например, вычисление константных выражений.

Далее идет оптимизация. Здесь инициализируется состояние планировщика и 
применяются более серьезные оптимизации. Например, удаление ненужных JOIN'ов.

После, когда все оптимизации выполнены находятся все возможные пути выполнения.
Например, в каждом запросе всегда возможен путь последовательного сканирования,
но также можно добавить и путь, использующий индекс.

Последний этап - выбор наиболее дешевого пути из созданных и создание для него
плана выполнения.

## Функции исходного кода

Говоря об исходном коде, можно выделить несколько основных функций и разграничить
эти этапы между ними.

На схеме справа можно заметить части запроса и функции, которые ответственны за эти
области. Используем bottom-up подход.

query\_planner - планировщик обхода таблиц. Он создает все scan узлы: SeqScan, 
    IndexScan и другие. При необходимости, он запускает планировщики для других
    подзапросов.

grouping\_planner - это обертка над query\_planner, которая добавляет разного
    рода обработку базового запроса: сортировка, группировка, лимиты/офсеты.
    Можно сказать, это реализация паттерна декоратор

subquery\_planner - это планировщик одного подзапроса. Причем, верхнеуровневный
    запрос - это тоже подзапрос, просто без родителя. Даже если у вас нет явных
    подзапросов, то весь запрос - это один большой подзапрос.

standard\_planner - входная точка всего планировщика. Он вызывает 
    subquery\_planner для верхнеуровнего запроса и дальше рекурсивно запускается
    для каждого подзапроса.

Слева тоже почти тоже самое, но добавлены комментарии что ДО и ПОСЛЕ функции.

## Узлы

Другая тема - структуры данных. 

В PostreSQL имеется своя система типов. Базовый тип - это узел, `Node`. 
`Node` - это абстрактный тип, единственная задача которого хранить тэг реального
типа. 

Тэг - это просто перечисление. Для каждого типа в этой иерархии имеется
свой тэг. Он составляется как префикс `T_` + название типа.

На схеме можно видеть этот базовый `Node` и его потомков. Здесь лишь малая часть,
всего узлов ближе к пятистам (500).

Я их разделил на такие подгруппы.

Вычисляемые узлы - это узлы, которые представляют какие-то выражения (слева
    направо): переменные (например, столбец таблицы), константы, операторы 
    (сложения, вычитания например) и т.д.

Контейнеры - это типы, которые служат хранилищем. Всего их 2 - `List` (список) и
    `Bitmapset` (множество чисел). `List` особенный в своем роде, так как
    у одной и той же структуры 4 разных тэга (для разных типов данных)

Узлы плана планировщика - это не узлы плана выполнения, они принадлежат планировщику
    и содержат базовый набор данных, для принятия им решений. Например, селективность
    пути

## Структуры планировщика

Говоря о планировщике, можно выделить несколько основных структур. На слайде
также можно видеть соотношение запроса и структур данных, ответственных за
определенные его части

Пойдем опять bottom-up подходом.

RestrictInfo - это какое-либо ограничение. Это может быть не только `WHERE`, но
    и условие JOIN'а. Вообще всякие ограничения в коде называются qualification
    (сокращенно qual), часто такое можно встретить.

RelOptInfo - это информация планировщика, касательно какого-либо отношения.
    Заметите, что я говорю не "таблица", так как RelOptInfo может быть создан
    и для подзапроса, или функции. Также, у него есть и брат близнец - 
    IndexOptInfo, информация об индексе.

PlannerInfo - это информация планировщика о всем подзапросе. Соответственно,
    создается для каждого подзапроса. Если у запроса есть подзапрос, то для
    него будет создан свой PlannerInfo

PlannerGlobal - это информация о всем запросе. С ней редко имеешь дело. Например,
    для назначения нового глобального ID.


# Идея оптимизации

Теперь мы знаем достаточно, чтобы реализовать какую-нибудь оптимизацию.
Предлагаю реализовать Constraint Exclusion - это оптимизация, которая учитывает
ограничения запроса.

Слева виден пример подобного запроса - никакое число не может быть одновременно
и больше и меньше нуля. 

Справа представлен паттерн ограничения, который мы будем искать в коде.
У нас имеется AND условие (BoolExpr) по обе стороны которого вызовы операторов
(OpExpr). Оба этих оператора являются негаторами друг друга, то есть
противоположные (больше и меньше или равно). У каждого оператора по 2 операнда:
левый - столбец таблицы, правый - константа. Причем они должны быть соответственно
равны.

## Лайв-кодинг

Давайте приступим.

В начале напишем функцию с ядром нашей логики. Она будет определять являются
ли 2 условия взаимоисключающими. На вход она будет принимать 2 `OpExpr`, и
возвращать `true`, если условия взаимоисключающие.

Первым делом проверим, что обе части оператора - это атрибут и константа. Для
это создадим вспомогательную функцию.

Оператор - это тоже функция со своими аргументами. Левая и правая часть - это
тоже аргументы. Их две. Поэтому количество аргументов тоже должно быть равно 2.

Далее, нам необходимо проверить типы операндов. Для проверки реального типа узла
существует макрос `IsA`.

С помощью него мы проверяем сначала атрибут (он представляется структурой `Var`),
а после константу (структура `Const`)

Получаем операнды левого и правого выражения. Теперь можем приступить к 
сравнению содержимого. 

Для проверки равенства узлов существует функция `equal`. Она проверяет равенство
узлов (хотя в сигнатуре используются указатели на `void`).

С помощью нее мы и проверим равенство.

Последний шаг - проверка операторов. Для этого мы можем воспользоваться системным
каталогом `pg_operator`. Каждый оператор может указать себе свой негатор (в 
столбце `oprnegate`).

В заголовочном файле `utils/lsyscache.h` объявлено множество часто полезных
функций, в частности `get_negator` - он возвращает Oid негатора для переданного
Oid оператора.

Осталось проверить операторы - они должны быть негаторами. Здесь достаточно одной
проверки.

Теперь наша функция готова. 

В самом начале планировщика мы выполняем предобработку дерева запроса. Нам
интересна функция `simplify_and_arguments`. Она вызывается для условий запроса.

Мы добавим такую логику - если находим в списке конфликтующие условия, то
превращаем их в константный `FALSE`.

Проверяем каждый элемент в переданном списке с предыдущим с помощью нашей логики.

Для начала проверяем этот запрос на ванильном постгресе. Видим, что производится
полное сканирование таблицы с условиями.

Теперь компилируем с нашими доработками и проверяем. Наша логика работает -
теперь мы сразу получаем пустой результат.

Но есть недостаток - если мы разобьем 2 условия на JOIN и WHERE, то ничего не
сработает. Причина в том, что мы работаем с деревом запроса и только условиями
WHERE - JOIN обрабатывается отдельно.

Чтобы починить это мы добавим нашу логику в работу планировщика. В PlannerInfo
имеется поле baserestrictinfo - он хранит список ограничений таблицы. Условия
из JOIN и WHERE хранятся вместе.

Напишем функцию `clamp_range_qualifiers`. Она будет проходить по всему списку
ограничений и схлопывать конфликтующие условия.

Логику реализуем следующим образом. Пройдемся по всему списку условий и если
найдем конфликтующие, то заменяем все на `FALSE`. Нет смысла учитывать остальные.

Логика примерно такая же, как и при работе с деревом запроса. Обходим весь
список и сравниваем текущий элемент с предыдущим. Разница в том, что сейчас
мы создадим новый список ограничений из единственного FALSE.

Нам нужны как минимум 2 условия. Сохраняем первое и начинаем итерироваться со 2.
Если они взаимоисключающие, то создаем новый список из 1 FALSE условия. Иначе,
сохраняем предыдущий узел и идем дальше.

Осталось понять куда добавлять эту логику.

Поле baserestrictinfo хранится в RelOptInfo, поэтому логично добавить ее, как
только будет создан сам RelOptInfo. Массив `simple_rel_array` хранит все
RelOptInfo, поэтому добавим функцию как раз после создания. Он создается в 
`add_base_rels_to_query`.

Добавили, теперь скомпилируем и запустим наш запрос. Он не сработал. Давайте
запустим отладчик и посмотрим почему так.

Поставим точку останова в нашей функции, и запустим запрос. Доходим до точки
выполнения и видим, что этот список пуст.

Причина в том, что многие структуры слишком большие и для оптимизации они
инициализируются постепенно и лениво. Единственный вариант для нового кода -
просто знать куда добавлять эту логику. Либо можно обмазываться ассертами и
писать тесты.

Чтобы это починить, надо добавить эту функцию туда, где `baserestrictinfo` будет
проинициализирован. Для простоты добавим ее в конец работы планировщика, перед
началом создания всех путей выполнения.

Скомпилируем и запустим. Все сработало.

Вообще эта оптимизация уже существует. Она включается GUC параметром
`constraint_exclusion`. Стоит отметить, что эта логика не изменяет состояние
списка ограничений (не удаляет, изменяет, добавляет ничего), а просто использует
это знание.

Это более мудрый подход. Как минимум потому что какая-то часть структуры может
зависеть от другой части (например, Var может указывать на RelOptInfo, который
мы просто взяли и удалили).

Вот мы и добавили свою оптимизацию в планировщик.

## Быстрое начало отладки

Дальше несколько советов, касательно работы с планировщиком. Первое - как быстро
начинать отладку.

Здесь 3 лайвхака. Первый - чтобы убрать запрос пароля при присоединении к процессу
можно выставить параметр конфигурации `kernel.yama.ptrace_scope` в 0 в файле 
`/etc/sysctl.d/10-ptrace.conf`. Он применится после перезагрузки навсегда. Есть
и другой вариант - записать 0 (например, через echo) в файл 
`/proc/sys/kernel/yama/ptrace_scope`. Он применит эти изменения сразу.

Второй - используем файл `.psqlrc`. В него запишем единственный
`select pg_backend_pid();`. После запуска он будет сразу выводиться.

Третий - используем такую конфигурацию отладки в `launch.json`. `program` - это
путь к файлу с отладочными символами, для Postgres это постоянный путь, можно
не указывать путь инсталляции. А в `processId` записывает переменную-команду.

Теперь при запуске отладчика нам потребуется просто ввести pid из psql

У себя я использовал схему посложнее - мне не прописывать pid, отладчик
подключится автоматически.

## Автоматизация

Раз мы заговорили про автоматизацию, то и про скрипты тоже стоит упомянуть. Это
не совсем относится к отладчику, но сильно помогает сократить длину итерации
отладки.

А если мы интегрируем их с VS Code с помощью тасок, то можно достичь быстрой
скорости разработки. Например, с помощью такой таски можно запускать сборку
нажатием шортката Ctrl + Shift + B.

В репозитории я выложу эти скрипты и файлы конфигурации для VS Code.

## Расширение

Последнее - это расширения. Раз мы говорим о планировщике, то самым полезным
тут является расширение PostgreSQL Hacker Helper.

Вы его видели в действии, когда смотрели внутрь `OpExpr` - искали `Var` и `Cons`.

Его главная фича - поддержка узлов. Он знает о них и, когда встречает такой, то
определяет его реальный тип, используя тэг, а потом отбражает уже реальный тип.

Кроме простого определения узлов, у него есть поддержка контейнеров (отображает
элементы списка и Bitmapset'а), а также знает о некоторых C-массивах - указателях
на массив, длина которых хранится в другом поле. Например, `simple_rel_array`.

Был момент, когда мне нужно было в окне `watch` просмативать элемент из массива
и подобная вложенность с определением узлов была где-то 5 элементов. Тогда я
потратил где-то 15 минут на это. С ним время сократилось буквально до пары секунд.

## Конец

На этом все. Спасибо за внимание. Если есть вопросы - задавайте.

