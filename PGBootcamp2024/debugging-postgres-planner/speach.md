# Речь
## Титульник

Всем привет. Меня зовут Сергей Соловьев. Я разработчик в компании Тантор. 
Разрабатываю одноименную СУБД.
Сегодня я расскажу об отладке планировщика.

## Обработка запроса

Для начала вспомним о пайплайне обработки запроса. В нем 4 этапа: парсинг
строки запроса, переписывание, планировние и выполнение.

Нам сегодня интересен 3 этап - планирование. Именно здесь и работает планировщик.

В его работе можно также выделить 4 этапа.

Первый этап - предобработка дерева запроса. На этом этапе выполняются общие 
оптимизации. Например, вычисление константных выражений.

Далее идет оптимизация. Здесь инициализируется состояние планировщика и 
применяются более серьезные оптимизации. Например, удаление ненужных JOIN'ов.

После, когда все оптимизации выполнены находятся все возможные пути выполнения.
Например, в каждом запросе всегда возможен путь последовательного сканирования,
но также можно добавить и путь, использующий индекс.

Последний этап - выбор наиболее дешевого пути из созданных и создание для него
плана выполнения.

## Функции исходного кода

На схеме справа можно заметить части запроса и функции, которые ответственны за
определенные области.

`query_planner` - планировщик обхода таблиц, определяет каким образом будут
    прочитаны данные. Он создает все scan узлы: SeqScan, IndexScan и другие. При
    необходимости, он запускает планировщики для других подзапросов.

`grouping_planner` - это обертка над `query_planner`, которая добавляет разного
    рода обработку: сортировка, группировка, лимиты/офсеты.

`subquery_planner` - это планировщик одного подзапроса. Даже если у вас нет явных
    подзапросов, то весь запрос - это один большой подзапрос.

`standard_planner` - входная точка всего планировщика. Он вызывает
    `subquery_planner` для верхнеуровнего запроса, после создает план.

Слева на слайде тоже почти тоже самое, но добавлены комментарии что происходит
ДО и ПОСЛЕ функции.

## Узлы

Другая тема - структуры данных.

В PostreSQL имеется своя система типов. Базовый тип - это узел, `Node`.
`Node` - это абстрактный тип, единственная задача которого хранить тэг реального
типа. Сам тэг - это простое перечисление.

Для каждого типа в этой иерархии имеется свой тэг. Он составляется как префикс
`T_` + название типа.

На схеме можно видеть этот базовый `Node` и его потомков. Здесь лишь малая часть,
всего узлов ближе к пятистам (500).

На схеме я выделил такие подгруппы.

Вычисляемые узлы - это узлы, которые представляют какие-то выражения (слева
    направо): переменные (например, столбец таблицы), константы, операторы
    (сложения, вычитания например).

Контейнеры - это структуры, которые служат хранилищем. Всего их 2 - `List` (список)
    и `Bitmapset` (множество чисел). `List` особенный в своем роде, так как
    у одной и той же структуры 4 разных тэга (для разных типов данных)

Узлы плана планировщика - это не узлы плана выполнения, они принадлежат планировщику
    и содержат базовый набор данных, для принятия им решений. Например,
    селективность пути

## Структуры планировщика

Говоря о планировщике, можно выделить несколько основных структур. На слайде
также можно видеть соотношение частей запроса и структур данных, ответственных
за них.

`RestrictInfo` - это какое-либо ограничение. Это может быть не только `WHERE`, но
    и условие JOIN'а. Вообще всякие ограничения в коде называются qualification
    (сокращенно qual), часто такое можно встретить.

`RelOptInfo` - это информация планировщика, касательно какого-либо отношения.
    Именно отношение, а не таблица, так как `RelOptInfo` может быть создан
    и для подзапроса, или функции. Также, у него есть и брат близнец -
    `IndexOptInfo`, информация об индексе.

`PlannerInfo` - это информация планировщика о подзапросе. Cоздается для
    каждого подзапроса.

`PlannerGlobal` - это информация о всем запросе. Используется не так часто,
    например, для назначения нового глобального ID.

# Идея оптимизации

Теперь мы знаем достаточно, чтобы реализовать какую-нибудь оптимизацию.
Предлагаю реализовать Constraint Exclusion - это оптимизация, которая учитывает
ограничения запроса.

Слева на слайде виден пример подобного запроса - никакое число не может быть
одновременно и больше и меньше нуля. Такой запрос должен ничего не вернуть.

Справа представлен паттерн узлов, который мы будем искать в коде. У нас имеется
AND условие (BoolExpr) по обе стороны которого вызовы операторов (OpExpr). Оба
этих оператора являются негаторами друг друга, то есть противоположные (больше и
меньше или равно). У каждого оператора по 2 операнда: левый - столбец таблицы,
правый - константа. Причем они должны быть соответственно равны.

### Лайв-кодинг

Перед началом давайте проверим поведение на ванильном Postgres.

Для проверки будем использовать этот запрос: `select ...`. Для начала проверяем
этот запрос на ванильном постгресе.

> Запуск запроса с explain

Видим, что производится полное сканирование таблицы с условиями. Приступим к
реализации.

Вначале напишем вспомогательную функцию - получение атрибута и константы из
OpExpr.

> Сигнатура функции extract_var_const_from_opexpr

Оператор - это тоже функция со своими аргументами. Левая и правая часть - это
тоже аргументы. Их две. Поэтому количество аргументов тоже должно быть равно 2.

> Проверка длины списка

Далее, нам необходимо проверить типы операндов. Для проверки реального типа узла
существует макрос `IsA`.
С помощью него мы проверяем сначала атрибут (он представляется структурой `Var`),
а после константу (структура `Const`)

> Проверка тэга первого и 2 узла

Теперь приступим к основной функции с ядром нашей логики. Она будет определять
являются ли 2 условия взаимоисключающими. На вход она будет принимать 2 `OpExpr`, и
возвращать `true`, если условия взаимоисключающие.

> Сигнатура основной функции

Первым делом проверим, что обе части оператора - это атрибут и константа. Для
этого используем ранее написанную функцию.

> Переменные + вызываем нашу функцию

Теперь можем приступить к сравнению содержимого. Для проверки равенства узлов
существует функция `equal`. Она проверяет равенство узлов, хотя в сигнатуре
используются указатели на `void`.

С помощью нее мы и проверим равенство.

> Проверка равенства Var и Const

Последний шаг - проверка операторов. Для этого мы можем воспользоваться системным
каталогом `pg_operator`. Каждый оператор может указать свой негатор (в столбце
`oprnegate`).

В заголовочном файле `utils/lsyscache.h` объявлено множество часто полезных
функций, в частности `get_negator` - он возвращает `Oid` негатора для переданного
оператора.

Осталось проверить операторы - они должны быть негаторами. Здесь достаточно одной
проверки.

> Пишем проверку opno == get_negator(opno)

Теперь наша функция готова.

Для начала добавим нашу оптимизацию в этап предобработки дерева запроса. Нам
интересна функция `simplify_and_arguments`. Она используется для оптимизации
списка из AND условий.

Мы добавим такую логику - если находим в списке конфликтующие условия, то
превращаем их в константный `FALSE`.

Реализация этой функции создает новый список условий из текущих. Нам надо обнаружить
ситуацию, когда последний элемент нового списка - это OpExpr, и текущий тоже.

> Добавляем условие OpExpr

Как только нашли, то проверяем что они взаимно исключающие.

> Добавляем проверку is_mutually_exclusive

Теперь компилируем с нашими доработками и проверяем.

> Компилирую и запускаю запрос

Наша логика работает - теперь мы сразу получаем пустой результат.

Но есть недостаток - если мы разобьем 2 условия на JOIN и WHERE, то ничего не
сработает. Причина в том, что мы работаем с деревом запроса и только условиями
WHERE - JOIN обрабатывается отдельно.

> Запускаю другой запрос

Чтобы починить это мы добавим нашу логику в работу планировщика. В `PlannerInfo`
имеется поле `baserestrictinfo` - он хранит список ограничений таблицы. Условия
из JOIN и WHERE хранятся вместе.

Напишем функцию `clamp_range_qualifiers`. Она будет проходить по всему списку
ограничений и при обнаружении конфликтующих условий заменяет все ограничения на
список из одного константного `FALSE`.

> Сигнатура clamp_range_qualifiers

Логика примерно такая же, как и при работе с деревом запроса. Обходим весь
список и сравниваем текущий элемент с предыдущим.

> Пишу prev_rinfo и начало итерации

Нам нужны как минимум 2 условия. Сохраняем первое и начинаем итерироваться со 2.
Если они взаимоисключающие, то создаем новый список из 1 FALSE условия. Иначе,
сохраняем предыдущий узел и идем дальше.

> Добавляю проверку на исключения и if/else

Для создания нового `RestrictInfo` можно использовать существующую функцию
`make_restrictinfo`. Для константы `FALSE` - `makeBoolConst`.

> Создание списка

Осталось понять куда добавлять эту логику.

Поле `baserestrictinfo` хранится в RelOptInfo, поэтому логично добавить ее, как
только будет создан сам `RelOptInfo`. Массив `simple_rel_array` хранит все
`RelOptInfo`, поэтому добавим функцию как раз после создания. Он создается в
`add_base_rels_to_query`.

> Добавляю clamp_range_qualifiers

Добавили, теперь скомпилируем и запустим наш запрос.

> Компилирую и запускаю запрос

Он не сработал. Давайте запустим отладчик и посмотрим почему так.

> Ставлю точку останова в clamp_range_qualifiers и запускаю запрос

Доходим до точки выполнения и видим, что этот список пуст.

Причина в том, что многие структуры слишком большие и для оптимизации они
инициализируются постепенно и лениво. Единственный вариант для нового кода -
просто знать куда добавлять эту логику. Либо можно обмазываться ассертами и
писать тесты.

Чтобы это починить, надо добавить эту функцию туда, где `baserestrictinfo` будет
проинициализирован. Для простоты добавим ее в конец работы планировщика, перед
началом создания всех путей выполнения.

> Изменяю положение `clamp_range_qualifiers`

Скомпилируем и запустим.

> Компиляция + запросы (2)

Все сработало.

Вообще эта оптимизация уже существует. Она включается GUC параметром
`constraint_exclusion`.

> Показываю где находится эта логика (реальная)

Стоит отметить, что эта логика не изменяет состояние
списка ограничений (не удаляет, изменяет, добавляет ничего), а просто использует
это знание.

Это более мудрый подход. Как минимум потому что какая-то часть структуры может
зависеть от другой части (например, Var может указывать на RelOptInfo, который
мы просто взяли и удалили).

Вот мы и добавили свою оптимизацию в планировщик.

## Быстрое начало отладки

Дальше несколько советов, касательно работы с планировщиком. Первое - как быстро
начинать отладку.

Здесь 3 лайвхака. Первый - чтобы убрать запрос пароля при присоединении к процессу
можно выставить параметр конфигурации `kernel.yama.ptrace_scope` в 0 в файле
`/etc/sysctl.d/10-ptrace.conf`.

Второй - используем файл `.psqlrc`. В него запишем единственный
`select pg_backend_pid();`. После запуска он будет сразу выводиться.

Третий (для VS Code) - используем такую конфигурацию отладки в `launch.json`.
`program` - это путь к файлу с отладочными символами, для Postgres это постоянный
путь, можно не указывать путь инсталляции. А в `processId` записывает
переменную-команду.

Теперь при запуске отладчика нам потребуется просто ввести pid из psql.

Есть схема посложнее - мне не прописывать pid, отладчик подключится автоматически.

## Автоматизация

Раз мы заговорили про автоматизацию, то и про скрипты тоже стоит упомянуть. Это
не совсем относится к отладчику, но сильно помогает сократить длину итерации
отладки.

А если мы интегрируем их с VS Code с помощью тасок, то можно достичь быстрой
скорости разработки. Например, с помощью такой таски можно запускать сборку
нажатием шортката Ctrl + Shift + B.

В репозитории я выложу эти скрипты и файлы конфигурации для VS Code.

## Расширение

Последнее - это расширения. Раз мы говорим о планировщике, то самым полезным
тут является расширение PostgreSQL Hacker Helper.

Вы его видели в действии, когда смотрели внутрь `OpExpr` - искали `Var` и `Cons`.

Его главная фича - поддержка узлов. Он знает о них и, когда встречает такой, то
определяет его реальный тип, используя тэг, а потом отбражает уже реальный тип.

Кроме простого определения узлов, у него есть поддержка контейнеров (отображает
элементы списка и Bitmapset'а), а также знает о некоторых C-массивах - указателях
на массив, длина которых хранится в другом поле. Например, `simple_rel_array`.

Был момент, когда мне нужно было в окне `watch` просмативать элемент из массива
и подобная вложенность с определением узлов была где-то 5 элементов. Тогда я
потратил где-то 15 минут на это. С ним время сократилось буквально до пары секунд.

## Конец

На этом все. Спасибо за внимание. Готов ответить на вопросы.
